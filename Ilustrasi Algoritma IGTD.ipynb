{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31c4d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata, spearmanr\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08995e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_distance_ranking(data, method='Pearson'):\n",
    "    '''\n",
    "    This function generates ranking of distances/dissimilarities between features for tabular data.\n",
    "\n",
    "    Input:\n",
    "    data: input data, n_sample by n_feature\n",
    "    method: 'Pearson' uses Pearson correlation coefficient to evaluate similarity between features;\n",
    "        'Spearman' uses Spearman correlation coefficient to evaluate similarity between features;\n",
    "        'set' uses Jaccard index to evaluate similarity between features that are binary variables.\n",
    "\n",
    "    Return:\n",
    "    ranking: symmetric ranking matrix based on dissimilarity\n",
    "    corr: matrix of distances between features\n",
    "    '''\n",
    "\n",
    "    num = data.shape[1]\n",
    "    if method == 'Pearson':\n",
    "        corr = np.corrcoef(np.transpose(data))\n",
    "    elif method == 'Spearman':\n",
    "        corr = spearmanr(data).correlation\n",
    "    elif method == 'Euclidean':\n",
    "        corr = squareform(pdist(np.transpose(data), metric='euclidean'))\n",
    "        corr = np.max(corr) - corr\n",
    "        corr = corr / np.max(corr)\n",
    "    # This is the new set operation to calculate similarity. It does not tolerate all-zero features.\n",
    "    elif method == 'set':\n",
    "        corr1 = np.dot(np.transpose(data), data)\n",
    "        corr2 = data.shape[0] - np.dot(np.transpose(1 - data), 1 - data)\n",
    "        corr = corr1 / corr2\n",
    "\n",
    "    corr = 1 - corr\n",
    "    corr = np.around(a=corr, decimals=10)\n",
    "\n",
    "    tril_id = np.tril_indices(num, k=-1)\n",
    "    rank = rankdata(corr[tril_id])\n",
    "    ranking = np.zeros((num, num))\n",
    "    ranking[tril_id] = rank\n",
    "    ranking = ranking + np.transpose(ranking)\n",
    "\n",
    "    return ranking, corr\n",
    "\n",
    "def generate_feature_distance_ranking_enhanced(data, method='Pearson'):\n",
    "    '''\n",
    "    This function generates ranking of distances/dissimilarities between features for tabular data.\n",
    "\n",
    "    Input:\n",
    "    data: input data, n_sample by n_feature\n",
    "    method: 'Pearson' uses Pearson correlation coefficient to evaluate similarity between features;\n",
    "        'Spearman' uses Spearman correlation coefficient to evaluate similarity between features;\n",
    "        'set' uses Jaccard index to evaluate similarity between features that are binary variables.\n",
    "\n",
    "    Return:\n",
    "    ranking: symmetric ranking matrix based on dissimilarity\n",
    "    corr: matrix of distances between features\n",
    "    '''\n",
    "\n",
    "    num = data.shape[1]\n",
    "    if method == 'Pearson':\n",
    "        corr = np.corrcoef(np.transpose(data))\n",
    "    elif method == 'Spearman':\n",
    "        corr = spearmanr(data).correlation\n",
    "    elif method == 'Euclidean':\n",
    "        corr = squareform(pdist(np.transpose(data), metric='euclidean'))\n",
    "        corr = np.max(corr) - corr\n",
    "        corr = corr / np.max(corr)\n",
    "    # This is the new set operation to calculate similarity. It does not tolerate all-zero features.\n",
    "    elif method == 'set':\n",
    "        corr1 = np.dot(np.transpose(data), data)\n",
    "        corr2 = data.shape[0] - np.dot(np.transpose(1 - data), 1 - data)\n",
    "        corr = corr1 / corr2\n",
    "\n",
    "    #corr = 1 - corr\n",
    "    corr = np.around(a=corr, decimals=10)\n",
    "\n",
    "    tril_id = np.tril_indices(num, k=-1)\n",
    "    rank = rankdata(corr[tril_id])\n",
    "    ranking = np.zeros((num, num))\n",
    "    ranking[tril_id] = rank\n",
    "    ranking = ranking + np.transpose(ranking)\n",
    "\n",
    "    return ranking, corr\n",
    "\n",
    "def generate_matrix_distance_ranking(num_r, num_c, method='Euclidean'):\n",
    "    '''\n",
    "    This function calculates the ranking of distances between all pairs of entries in a matrix of size num_r by num_c.\n",
    "\n",
    "    Input:\n",
    "    num_r: number of rows in the matrix\n",
    "    num_c: number of columns in the matrix\n",
    "    method: method used to calculate distance. Can be 'Euclidean' or 'Manhattan'.\n",
    "\n",
    "    Return:\n",
    "    coordinate: num_r * num_c by 2 matrix giving the coordinates of elements in the matrix.\n",
    "    ranking: a num_r * num_c by num_r * num_c matrix giving the ranking of pair-wise distance.\n",
    "\n",
    "    '''\n",
    "\n",
    "    # generate the coordinates of elements in a matrix\n",
    "    for r in range(num_r):\n",
    "        if r == 0:\n",
    "            coordinate = np.transpose(\n",
    "                np.vstack((np.zeros(num_c), range(num_c))))\n",
    "        else:\n",
    "            coordinate = np.vstack((coordinate, np.transpose(\n",
    "                np.vstack((np.ones(num_c) * r, range(num_c))))))\n",
    "\n",
    "    # calculate the closeness of the elements\n",
    "    num = num_r * num_c\n",
    "    cord_dist = np.zeros((num, num))\n",
    "    if method == 'Euclidean':\n",
    "        for i in range(num):\n",
    "            cord_dist[i, :] = np.sqrt(np.square(coordinate[i, 0] * np.ones(num) - coordinate[:, 0]) +\n",
    "                                      np.square(coordinate[i, 1] * np.ones(num) - coordinate[:, 1]))\n",
    "    elif method == 'Manhattan':\n",
    "        for i in range(num):\n",
    "            cord_dist[i, :] = np.abs(coordinate[i, 0] * np.ones(num) - coordinate[:, 0]) + \\\n",
    "                np.abs(coordinate[i, 1] * np.ones(num) - coordinate[:, 1])\n",
    "\n",
    "    # generate the ranking based on distance\n",
    "    tril_id = np.tril_indices(num, k=-1)\n",
    "    rank = rankdata(cord_dist[tril_id])\n",
    "    ranking = np.zeros((num, num))\n",
    "    ranking[tril_id] = rank\n",
    "    ranking = ranking + np.transpose(ranking)\n",
    "\n",
    "    coordinate = np.int64(coordinate)\n",
    "    return (coordinate[:, 0], coordinate[:, 1]), ranking\n",
    "\n",
    "\n",
    "def IGTD_absolute_error(source, target, max_step=1000, switch_t=0, val_step=50, min_gain=0.00001, random_state=1,\n",
    "                        save_folder=None, file_name=''):\n",
    "    '''\n",
    "    This function switches the order of rows (columns) in the source ranking matrix to make it similar to the target\n",
    "    ranking matrix. In each step, the algorithm randomly picks a row that has not been switched with others for\n",
    "    the longest time and checks all possible switch of this row, and selects the switch that reduces the\n",
    "    dissimilarity most. Dissimilarity (i.e. the error) is the summation of absolute difference of\n",
    "    lower triangular elements between the rearranged source ranking matrix and the target ranking matrix.\n",
    "\n",
    "    Input:\n",
    "    source: a symmetric ranking matrix with zero diagonal elements.\n",
    "    target: a symmetric ranking matrix with zero diagonal elements. 'source' and 'target' should have the same size.\n",
    "    max_step: the maximum steps that the algorithm should run if never converges.\n",
    "    switch_t: the threshold to determine whether switch should happen\n",
    "    val_step: number of steps for checking gain on the objective function to determine convergence\n",
    "    min_gain: if the objective function is not improved more than 'min_gain' in 'val_step' steps,\n",
    "        the algorithm terminates.\n",
    "    random_state: for setting random seed.\n",
    "    save_folder: a path to save the picture of source ranking matrix in the optimization process.\n",
    "    file_name: a string as part of the file names for saving results\n",
    "\n",
    "    Return:\n",
    "    index_record: indices to rearrange the rows(columns) in source obtained the optimization process\n",
    "    err_record: error obtained in the optimization process\n",
    "    run_time: the time at which each step is completed in the optimization process\n",
    "    '''\n",
    "\n",
    "    np.random.RandomState(seed=random_state)\n",
    "    if save_folder is not None:\n",
    "        if os.path.exists(save_folder):\n",
    "            shutil.rmtree(save_folder)\n",
    "        os.mkdir(save_folder)\n",
    "\n",
    "    source = source.copy()\n",
    "    num = source.shape[0]\n",
    "    tril_id = np.tril_indices(num, k=-1)\n",
    "    index = np.array(range(num))\n",
    "    index_record = np.empty((max_step + 1, num))\n",
    "    index_record.fill(np.nan)\n",
    "    index_record[0, :] = index.copy()\n",
    "\n",
    "    # calculate the error associated with each row\n",
    "    err_v = np.empty(num)\n",
    "    err_v.fill(np.nan)\n",
    "    for i in range(num):\n",
    "        err_v[i] = np.sum(np.abs(source[i, 0:i] - target[i, 0:i])) + \\\n",
    "            np.sum(np.abs(source[(i + 1):, i] - target[(i + 1):, i]))\n",
    "\n",
    "    step_record = -np.ones(num)\n",
    "    err_record = [np.sum(abs(source[tril_id] - target[tril_id]))]\n",
    "    pre_err = err_record[0]\n",
    "    t1 = time.time()\n",
    "    run_time = [0]\n",
    "\n",
    "    for s in range(max_step):\n",
    "        delta = np.ones(num) * np.inf\n",
    "\n",
    "        # randomly pick a row that has not been considered for the longest time\n",
    "        idr = np.where(step_record == np.min(step_record))[0]\n",
    "        ii = idr[np.random.permutation(len(idr))[0]]\n",
    "\n",
    "        for jj in range(num):\n",
    "            if jj == ii:\n",
    "                continue\n",
    "\n",
    "            if ii < jj:\n",
    "                i = ii\n",
    "                j = jj\n",
    "            else:\n",
    "                i = jj\n",
    "                j = ii\n",
    "\n",
    "            err_ori = err_v[i] + err_v[j] - np.abs(source[j, i] - target[j, i])\n",
    "\n",
    "            err_i = np.sum(np.abs(source[j, :i] - target[i, :i])) + \\\n",
    "                np.sum(np.abs(source[(i + 1):j, j] - target[(i + 1):j, i])) + \\\n",
    "                np.sum(np.abs(source[(j + 1):, j] - target[(j + 1):, i])\n",
    "                       ) + np.abs(source[i, j] - target[j, i])\n",
    "            err_j = np.sum(np.abs(source[i, :i] - target[j, :i])) + \\\n",
    "                np.sum(np.abs(source[i, (i + 1):j] - target[j, (i + 1):j])) + \\\n",
    "                np.sum(np.abs(source[(j + 1):, i] - target[(j + 1):, j])\n",
    "                       ) + np.abs(source[i, j] - target[j, i])\n",
    "            err_test = err_i + err_j - np.abs(source[i, j] - target[j, i])\n",
    "\n",
    "            delta[jj] = err_test - err_ori\n",
    "\n",
    "        delta_norm = delta / pre_err\n",
    "        id = np.where(delta_norm <= switch_t)[0]\n",
    "        if len(id) > 0:\n",
    "            jj = np.argmin(delta)\n",
    "\n",
    "            # Update the error associated with each row\n",
    "            if ii < jj:\n",
    "                i = ii\n",
    "                j = jj\n",
    "            else:\n",
    "                i = jj\n",
    "                j = ii\n",
    "            for k in range(num):\n",
    "                if k < i:\n",
    "                    err_v[k] = err_v[k] - np.abs(source[i, k] - target[i, k]) - np.abs(source[j, k] - target[j, k]) + \\\n",
    "                        np.abs(source[j, k] - target[i, k]) + \\\n",
    "                        np.abs(source[i, k] - target[j, k])\n",
    "                elif k == i:\n",
    "                    err_v[k] = np.sum(np.abs(source[j, :i] - target[i, :i])) + \\\n",
    "                        np.sum(np.abs(source[(i + 1):j, j] - target[(i + 1):j, i])) + \\\n",
    "                        np.sum(np.abs(\n",
    "                            source[(j + 1):, j] - target[(j + 1):, i])) + np.abs(source[i, j] - target[j, i])\n",
    "                elif k < j:\n",
    "                    err_v[k] = err_v[k] - np.abs(source[k, i] - target[k, i]) - np.abs(source[j, k] - target[j, k]) + \\\n",
    "                        np.abs(source[k, j] - target[k, i]) + \\\n",
    "                        np.abs(source[i, k] - target[j, k])\n",
    "                elif k == j:\n",
    "                    err_v[k] = np.sum(np.abs(source[i, :i] - target[j, :i])) + \\\n",
    "                        np.sum(np.abs(source[i, (i + 1):j] - target[j, (i + 1):j])) + \\\n",
    "                        np.sum(np.abs(\n",
    "                            source[(j + 1):, i] - target[(j + 1):, j])) + np.abs(source[i, j] - target[j, i])\n",
    "                else:\n",
    "                    err_v[k] = err_v[k] - np.abs(source[k, i] - target[k, i]) - np.abs(source[k, j] - target[k, j]) + \\\n",
    "                        np.abs(source[k, j] - target[k, i]) + \\\n",
    "                        np.abs(source[k, i] - target[k, j])\n",
    "\n",
    "            # switch rows i and j\n",
    "            ii_v = source[ii, :].copy()\n",
    "            jj_v = source[jj, :].copy()\n",
    "            source[ii, :] = jj_v\n",
    "            source[jj, :] = ii_v\n",
    "            ii_v = source[:, ii].copy()\n",
    "            jj_v = source[:, jj].copy()\n",
    "            source[:, ii] = jj_v\n",
    "            source[:, jj] = ii_v\n",
    "            err = delta[jj] + pre_err\n",
    "\n",
    "            # update rearrange index\n",
    "            t = index[ii]\n",
    "            index[ii] = index[jj]\n",
    "            index[jj] = t\n",
    "\n",
    "            # update step record\n",
    "            step_record[ii] = s\n",
    "            step_record[jj] = s\n",
    "        else:\n",
    "            # error is not changed due to no switch\n",
    "            err = pre_err\n",
    "\n",
    "            # update step record\n",
    "            step_record[ii] = s\n",
    "\n",
    "        err_record.append(err)\n",
    "        #print('Step ' + str(s) + ' err: ' + str(err))\n",
    "        index_record[s + 1, :] = index.copy()\n",
    "        run_time.append(time.time() - t1)\n",
    "\n",
    "        if s > val_step:\n",
    "            if np.sum((err_record[-val_step - 1] - np.array(err_record[(-val_step):])) / err_record[\n",
    "                    -val_step - 1] >= min_gain) == 0:\n",
    "                break\n",
    "\n",
    "        pre_err = err\n",
    "\n",
    "    index_record = index_record[:len(err_record), :].astype(int)\n",
    "    if save_folder is not None:\n",
    "        pd.DataFrame(index_record).to_csv(save_folder + '/' + file_name + '_index.txt', header=False, index=False,\n",
    "                                          sep='\\t', line_terminator='\\r\\n')\n",
    "        pd.DataFrame(np.transpose(np.vstack((err_record, np.array(range(s + 2))))),\n",
    "                     columns=['error', 'steps']).to_csv(save_folder + '/' + file_name + '_error_and_step.txt',\n",
    "                                                        header=True, index=False, sep='\\t', line_terminator='\\r\\n')\n",
    "        pd.DataFrame(np.transpose(np.vstack((err_record, run_time))), columns=['error', 'run_time']).to_csv(\n",
    "            save_folder + '/' + file_name + '_error_and_time.txt', header=True, index=False, sep='\\t',\n",
    "            line_terminator='\\r\\n')\n",
    "\n",
    "    return index_record, err_record, run_time\n",
    "\n",
    "\n",
    "def IGTD_square_error(source, target, max_step=1000, switch_t=0, val_step=50, min_gain=0.00001, random_state=1,\n",
    "                      save_folder=None, file_name=''):\n",
    "    '''\n",
    "    This function switches the order of rows (columns) in the source ranking matrix to make it similar to the target\n",
    "    ranking matrix. In each step, the algorithm randomly picks a row that has not been switched with others for\n",
    "    the longest time and checks all possible switch of this row, and selects the switch that reduces the\n",
    "    dissimilarity most. Dissimilarity (i.e. the error) is the summation of squared difference of\n",
    "    lower triangular elements between the rearranged source ranking matrix and the target ranking matrix.\n",
    "\n",
    "    Input:\n",
    "    source: a symmetric ranking matrix with zero diagonal elements.\n",
    "    target: a symmetric ranking matrix with zero diagonal elements. 'source' and 'target' should have the same size.\n",
    "    max_step: the maximum steps that the algorithm should run if never converges.\n",
    "    switch_t: the threshold to determine whether switch should happen\n",
    "    val_step: number of steps for checking gain on the objective function to determine convergence\n",
    "    min_gain: if the objective function is not improved more than 'min_gain' in 'val_step' steps,\n",
    "        the algorithm terminates.\n",
    "    random_state: for setting random seed.\n",
    "    save_folder: a path to save the picture of source ranking matrix in the optimization process.\n",
    "    file_name: a string as part of the file names for saving results\n",
    "\n",
    "    Return:\n",
    "    index_record: ordering index to rearrange the rows(columns) in 'source' in the optimization process\n",
    "    err_record: the error history in the optimization process\n",
    "    run_time: the time at which each step is finished in the optimization process\n",
    "    '''\n",
    "\n",
    "    np.random.RandomState(seed=random_state)\n",
    "    if save_folder is not None:\n",
    "        if os.path.exists(save_folder):\n",
    "            shutil.rmtree(save_folder)\n",
    "        os.mkdir(save_folder)\n",
    "\n",
    "    source = source.copy()\n",
    "    num = source.shape[0]\n",
    "    tril_id = np.tril_indices(num, k=-1)\n",
    "    index = np.array(range(num))\n",
    "    index_record = np.empty((max_step + 1, num))\n",
    "    index_record.fill(np.nan)\n",
    "    index_record[0, :] = index.copy()\n",
    "\n",
    "    # calculate the error associated with each row\n",
    "    err_v = np.empty(num)\n",
    "    err_v.fill(np.nan)\n",
    "    for i in range(num):\n",
    "        err_v[i] = np.sum(np.square(source[i, 0:i] - target[i, 0:i])) + \\\n",
    "            np.sum(np.square(source[(i + 1):, i] - target[(i + 1):, i]))\n",
    "\n",
    "    step_record = -np.ones(num)\n",
    "    err_record = [np.sum(np.square(source[tril_id] - target[tril_id]))]\n",
    "    pre_err = err_record[0]\n",
    "    t1 = time.time()\n",
    "    run_time = [0]\n",
    "\n",
    "    for s in range(max_step):\n",
    "        delta = np.ones(num) * np.inf\n",
    "\n",
    "        # randomly pick a row that has not been considered for the longest time\n",
    "        idr = np.where(step_record == np.min(step_record))[0]\n",
    "        ii = idr[np.random.permutation(len(idr))[0]]\n",
    "\n",
    "        for jj in range(num):\n",
    "            if jj == ii:\n",
    "                continue\n",
    "\n",
    "            if ii < jj:\n",
    "                i = ii\n",
    "                j = jj\n",
    "            else:\n",
    "                i = jj\n",
    "                j = ii\n",
    "\n",
    "            err_ori = err_v[i] + err_v[j] - \\\n",
    "                np.square(source[j, i] - target[j, i])\n",
    "\n",
    "            err_i = np.sum(np.square(source[j, :i] - target[i, :i])) + \\\n",
    "                np.sum(np.square(source[(i + 1):j, j] - target[(i + 1):j, i])) + \\\n",
    "                np.sum(np.square(source[(j + 1):, j] - target[(j + 1):, i])\n",
    "                       ) + np.square(source[i, j] - target[j, i])\n",
    "            err_j = np.sum(np.square(source[i, :i] - target[j, :i])) + \\\n",
    "                np.sum(np.square(source[i, (i + 1):j] - target[j, (i + 1):j])) + \\\n",
    "                np.sum(np.square(source[(j + 1):, i] - target[(j + 1):, j])\n",
    "                       ) + np.square(source[i, j] - target[j, i])\n",
    "            err_test = err_i + err_j - np.square(source[i, j] - target[j, i])\n",
    "\n",
    "            delta[jj] = err_test - err_ori\n",
    "\n",
    "        delta_norm = delta / pre_err\n",
    "        id = np.where(delta_norm <= switch_t)[0]\n",
    "        if len(id) > 0:\n",
    "            jj = np.argmin(delta)\n",
    "\n",
    "            # Update the error associated with each row\n",
    "            if ii < jj:\n",
    "                i = ii\n",
    "                j = jj\n",
    "            else:\n",
    "                i = jj\n",
    "                j = ii\n",
    "            for k in range(num):\n",
    "                if k < i:\n",
    "                    err_v[k] = err_v[k] - np.square(source[i, k] - target[i, k]) - np.square(source[j, k] - target[j, k]) + \\\n",
    "                        np.square(source[j, k] - target[i, k]) + \\\n",
    "                        np.square(source[i, k] - target[j, k])\n",
    "                elif k == i:\n",
    "                    err_v[k] = np.sum(np.square(source[j, :i] - target[i, :i])) + \\\n",
    "                        np.sum(np.square(source[(i + 1):j, j] - target[(i + 1):j, i])) + \\\n",
    "                        np.sum(np.square(\n",
    "                            source[(j + 1):, j] - target[(j + 1):, i])) + np.square(source[i, j] - target[j, i])\n",
    "                elif k < j:\n",
    "                    err_v[k] = err_v[k] - np.square(source[k, i] - target[k, i]) - np.square(source[j, k] - target[j, k]) + \\\n",
    "                        np.square(source[k, j] - target[k, i]) + \\\n",
    "                        np.square(source[i, k] - target[j, k])\n",
    "                elif k == j:\n",
    "                    err_v[k] = np.sum(np.square(source[i, :i] - target[j, :i])) + \\\n",
    "                        np.sum(np.square(source[i, (i + 1):j] - target[j, (i + 1):j])) + \\\n",
    "                        np.sum(np.square(\n",
    "                            source[(j + 1):, i] - target[(j + 1):, j])) + np.square(source[i, j] - target[j, i])\n",
    "                else:\n",
    "                    err_v[k] = err_v[k] - np.square(source[k, i] - target[k, i]) - np.square(source[k, j] - target[k, j]) + \\\n",
    "                        np.square(source[k, j] - target[k, i]) + \\\n",
    "                        np.square(source[k, i] - target[k, j])\n",
    "\n",
    "            # switch rows i and j\n",
    "            ii_v = source[ii, :].copy()\n",
    "            jj_v = source[jj, :].copy()\n",
    "            source[ii, :] = jj_v\n",
    "            source[jj, :] = ii_v\n",
    "            ii_v = source[:, ii].copy()\n",
    "            jj_v = source[:, jj].copy()\n",
    "            source[:, ii] = jj_v\n",
    "            source[:, jj] = ii_v\n",
    "            err = delta[jj] + pre_err\n",
    "\n",
    "            # update rearrange index\n",
    "            t = index[ii]\n",
    "            index[ii] = index[jj]\n",
    "            index[jj] = t\n",
    "\n",
    "            # update step record\n",
    "            step_record[ii] = s\n",
    "            step_record[jj] = s\n",
    "        else:\n",
    "            # error is not changed due to no switch\n",
    "            err = pre_err\n",
    "\n",
    "            # update step record\n",
    "            step_record[ii] = s\n",
    "\n",
    "        err_record.append(err)\n",
    "        #print('Step ' + str(s) + ' err: ' + str(err))\n",
    "        index_record[s + 1, :] = index.copy()\n",
    "        run_time.append(time.time() - t1)\n",
    "\n",
    "        if s > val_step:\n",
    "            if np.sum((err_record[-val_step - 1] - np.array(err_record[(-val_step):])) / err_record[\n",
    "                    -val_step - 1] >= min_gain) == 0:\n",
    "                break\n",
    "\n",
    "        pre_err = err\n",
    "\n",
    "    index_record = index_record[:len(err_record), :].astype(int)\n",
    "    if save_folder is not None:\n",
    "        pd.DataFrame(index_record).to_csv(save_folder + '/' + file_name + '_index.txt', header=False, index=False,\n",
    "                                          sep='\\t', line_terminator='\\r\\n')\n",
    "        pd.DataFrame(np.transpose(np.vstack((err_record, np.array(range(s + 2))))),\n",
    "                     columns=['error', 'steps']).to_csv(save_folder + '/' + file_name + '_error_and_step.txt',\n",
    "                                                        header=True, index=False, sep='\\t', line_terminator='\\r\\n')\n",
    "        pd.DataFrame(np.transpose(np.vstack((err_record, run_time))), columns=['error', 'run_time']).to_csv(\n",
    "            save_folder + '/' + file_name + '_error_and_time.txt', header=True, index=False, sep='\\t',\n",
    "            line_terminator='\\r\\n')\n",
    "\n",
    "    return index_record, err_record, run_time\n",
    "\n",
    "\n",
    "def IGTD(source, target, err_measure='abs', max_step=1000, switch_t=0, val_step=50, min_gain=0.00001, random_state=1,\n",
    "         save_folder=None, file_name=''):\n",
    "    '''\n",
    "    This is just a wrapper function that wraps the two search functions using different error measures.\n",
    "    '''\n",
    "\n",
    "    if err_measure == 'abs':\n",
    "        index_record, err_record, run_time = IGTD_absolute_error(source=source,\n",
    "                                                                 target=target, max_step=max_step, switch_t=switch_t, val_step=val_step, min_gain=min_gain,\n",
    "                                                                 random_state=random_state, save_folder=save_folder, file_name=file_name)\n",
    "    if err_measure == 'squared':\n",
    "        index_record, err_record, run_time = IGTD_square_error(source=source,\n",
    "                                                               target=target, max_step=max_step, switch_t=switch_t, val_step=val_step, min_gain=min_gain,\n",
    "                                                               random_state=random_state, save_folder=save_folder, file_name=file_name)\n",
    "\n",
    "    return index_record, err_record, run_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8987326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.17022005e-01, 7.20324493e-01, 1.14374817e-04, 3.02332573e-01,\n",
       "        1.46755891e-01, 9.23385948e-02],\n",
       "       [1.86260211e-01, 3.45560727e-01, 3.96767474e-01, 5.38816734e-01,\n",
       "        4.19194514e-01, 6.85219500e-01],\n",
       "       [2.04452250e-01, 8.78117436e-01, 2.73875932e-02, 6.70467510e-01,\n",
       "        4.17304802e-01, 5.58689828e-01],\n",
       "       [1.40386939e-01, 1.98101489e-01, 8.00744569e-01, 9.68261576e-01,\n",
       "        3.13424178e-01, 6.92322616e-01],\n",
       "       [8.76389152e-01, 8.94606664e-01, 8.50442114e-02, 3.90547832e-02,\n",
       "        1.69830420e-01, 8.78142503e-01],\n",
       "       [9.83468338e-02, 4.21107625e-01, 9.57889530e-01, 5.33165285e-01,\n",
       "        6.91877114e-01, 3.15515631e-01],\n",
       "       [6.86500928e-01, 8.34625672e-01, 1.82882773e-02, 7.50144315e-01,\n",
       "        9.88861089e-01, 7.48165654e-01],\n",
       "       [2.80443992e-01, 7.89279328e-01, 1.03226007e-01, 4.47893526e-01,\n",
       "        9.08595503e-01, 2.93614148e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.rand(8, 6)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70903fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.,  1., 14., 13., 11.,  2.],\n",
       "        [ 1.,  0., 15., 12.,  5.,  8.],\n",
       "        [14., 15.,  0.,  3.,  7.,  9.],\n",
       "        [13., 12.,  3.,  0.,  4.,  6.],\n",
       "        [11.,  5.,  7.,  4.,  0., 10.],\n",
       "        [ 2.,  8.,  9.,  6., 10.,  0.]]),\n",
       " array([[0.        , 0.33489146, 1.61278693, 1.55405467, 1.07250942,\n",
       "         0.56144746],\n",
       "        [0.33489146, 0.        , 1.85490468, 1.51284323, 0.85546831,\n",
       "         1.00558514],\n",
       "        [1.61278693, 1.85490468, 0.        , 0.58737637, 0.99257009,\n",
       "         1.0153641 ],\n",
       "        [1.55405467, 1.51284323, 0.58737637, 0.        , 0.64979859,\n",
       "         0.86573863],\n",
       "        [1.07250942, 0.85546831, 0.99257009, 0.64979859, 0.        ,\n",
       "         1.06034672],\n",
       "        [0.56144746, 1.00558514, 1.0153641 , 0.86573863, 1.06034672,\n",
       "         0.        ]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_feature_distance_ranking(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb153b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0., 15.,  2.,  3.,  5., 14.],\n",
       "        [15.,  0.,  1.,  4., 11.,  8.],\n",
       "        [ 2.,  1.,  0., 13.,  9.,  7.],\n",
       "        [ 3.,  4., 13.,  0., 12., 10.],\n",
       "        [ 5., 11.,  9., 12.,  0.,  6.],\n",
       "        [14.,  8.,  7., 10.,  6.,  0.]]),\n",
       " array([[ 1.        ,  0.66510854, -0.61278693, -0.55405467, -0.07250942,\n",
       "          0.43855254],\n",
       "        [ 0.66510854,  1.        , -0.85490468, -0.51284323,  0.14453169,\n",
       "         -0.00558514],\n",
       "        [-0.61278693, -0.85490468,  1.        ,  0.41262363,  0.00742991,\n",
       "         -0.0153641 ],\n",
       "        [-0.55405467, -0.51284323,  0.41262363,  1.        ,  0.35020141,\n",
       "          0.13426137],\n",
       "        [-0.07250942,  0.14453169,  0.00742991,  0.35020141,  1.        ,\n",
       "         -0.06034672],\n",
       "        [ 0.43855254, -0.00558514, -0.0153641 ,  0.13426137, -0.06034672,\n",
       "          1.        ]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_feature_distance_ranking_enhanced(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30de2c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 0, 1, 1, 2, 2], dtype=int64),\n",
       "  array([0, 1, 0, 1, 0, 1], dtype=int64)),\n",
       " array([[ 0. ,  4. ,  4. ,  9.5, 12.5, 14.5],\n",
       "        [ 4. ,  0. ,  9.5,  4. , 14.5, 12.5],\n",
       "        [ 4. ,  9.5,  0. ,  4. ,  4. ,  9.5],\n",
       "        [ 9.5,  4. ,  4. ,  0. ,  9.5,  4. ],\n",
       "        [12.5, 14.5,  4. ,  9.5,  0. ,  4. ],\n",
       "        [14.5, 12.5,  9.5,  4. ,  4. ,  0. ]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_matrix_distance_ranking(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "755bc690",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking, _ = generate_feature_distance_ranking(X)\n",
    "feature_ranking_en, _ = generate_feature_distance_ranking_enhanced(X)\n",
    "matrix_coordinate, matrix_dist_ranking = generate_matrix_distance_ranking(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e65f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4, 5],\n",
       "        [4, 1, 2, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5],\n",
       "        [4, 2, 1, 3, 0, 5]]),\n",
       " [565.0,\n",
       "  481.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0,\n",
       "  202.0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_record, err_record, run_time = IGTD(source=feature_ranking, target=matrix_dist_ranking, err_measure='squared')\n",
    "index_record, err_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c7b0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 3, 4, 5],\n",
       "        [5, 1, 2, 3, 4, 0],\n",
       "        [2, 1, 5, 3, 4, 0],\n",
       "        [2, 1, 5, 3, 4, 0],\n",
       "        [3, 1, 5, 2, 4, 0],\n",
       "        [3, 1, 5, 2, 4, 0],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5],\n",
       "        [3, 1, 0, 2, 4, 5]]),\n",
       " [487.0,\n",
       "  329.0,\n",
       "  288.0,\n",
       "  288.0,\n",
       "  249.0,\n",
       "  249.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0,\n",
       "  144.0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_record_en, err_record_en, run_time_en = IGTD(source=feature_ranking_en, target=matrix_dist_ranking, err_measure='squared')\n",
    "index_record_en, err_record_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bb86a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[3.02332573e-01, 7.20324493e-01],\n",
       "         [4.17022005e-01, 1.14374817e-04],\n",
       "         [1.46755891e-01, 9.23385948e-02]],\n",
       " \n",
       "        [[5.38816734e-01, 3.45560727e-01],\n",
       "         [1.86260211e-01, 3.96767474e-01],\n",
       "         [4.19194514e-01, 6.85219500e-01]],\n",
       " \n",
       "        [[6.70467510e-01, 8.78117436e-01],\n",
       "         [2.04452250e-01, 2.73875932e-02],\n",
       "         [4.17304802e-01, 5.58689828e-01]],\n",
       " \n",
       "        [[9.68261576e-01, 1.98101489e-01],\n",
       "         [1.40386939e-01, 8.00744569e-01],\n",
       "         [3.13424178e-01, 6.92322616e-01]],\n",
       " \n",
       "        [[3.90547832e-02, 8.94606664e-01],\n",
       "         [8.76389152e-01, 8.50442114e-02],\n",
       "         [1.69830420e-01, 8.78142503e-01]],\n",
       " \n",
       "        [[5.33165285e-01, 4.21107625e-01],\n",
       "         [9.83468338e-02, 9.57889530e-01],\n",
       "         [6.91877114e-01, 3.15515631e-01]],\n",
       " \n",
       "        [[7.50144315e-01, 8.34625672e-01],\n",
       "         [6.86500928e-01, 1.82882773e-02],\n",
       "         [9.88861089e-01, 7.48165654e-01]],\n",
       " \n",
       "        [[4.47893526e-01, 7.89279328e-01],\n",
       "         [2.80443992e-01, 1.03226007e-01],\n",
       "         [9.08595503e-01, 2.93614148e-01]]]),\n",
       " array([[[1.46755891e-01, 1.14374817e-04],\n",
       "         [7.20324493e-01, 3.02332573e-01],\n",
       "         [4.17022005e-01, 9.23385948e-02]],\n",
       " \n",
       "        [[4.19194514e-01, 3.96767474e-01],\n",
       "         [3.45560727e-01, 5.38816734e-01],\n",
       "         [1.86260211e-01, 6.85219500e-01]],\n",
       " \n",
       "        [[4.17304802e-01, 2.73875932e-02],\n",
       "         [8.78117436e-01, 6.70467510e-01],\n",
       "         [2.04452250e-01, 5.58689828e-01]],\n",
       " \n",
       "        [[3.13424178e-01, 8.00744569e-01],\n",
       "         [1.98101489e-01, 9.68261576e-01],\n",
       "         [1.40386939e-01, 6.92322616e-01]],\n",
       " \n",
       "        [[1.69830420e-01, 8.50442114e-02],\n",
       "         [8.94606664e-01, 3.90547832e-02],\n",
       "         [8.76389152e-01, 8.78142503e-01]],\n",
       " \n",
       "        [[6.91877114e-01, 9.57889530e-01],\n",
       "         [4.21107625e-01, 5.33165285e-01],\n",
       "         [9.83468338e-02, 3.15515631e-01]],\n",
       " \n",
       "        [[9.88861089e-01, 1.82882773e-02],\n",
       "         [8.34625672e-01, 7.50144315e-01],\n",
       "         [6.86500928e-01, 7.48165654e-01]],\n",
       " \n",
       "        [[9.08595503e-01, 1.03226007e-01],\n",
       "         [7.89279328e-01, 4.47893526e-01],\n",
       "         [2.80443992e-01, 2.93614148e-01]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_IGTD_en = np.reshape(X[:,index_record_en[-1]], (-1, 3, 2))\n",
    "X_IGTD = np.reshape(X[:,index_record[-1]], (-1, 3, 2))\n",
    "\n",
    "X_IGTD_en, X_IGTD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6ae42f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 57)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(err_record), len(err_record_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dbf5403",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('IGTD Illustration.csv', X, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72613776",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('feature_rank.csv', feature_ranking, delimiter=',', fmt='%s')\n",
    "np.savetxt('feature_rank_en.csv', feature_ranking_en, delimiter=',', fmt='%s')\n",
    "np.savetxt('matrix_dist_rank.csv', matrix_dist_ranking, delimiter=',', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4821c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[565.0, 527.0, 525.0, 585.0, 502.0, 555.0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = []\n",
    "for i in range(6):\n",
    "    temp = feature_ranking.copy()\n",
    "    temp[:, 0], temp[:, i] = temp[:, i], temp[:, 0]\n",
    "    temp[0, :], temp[i, :] = temp[i, :], temp[0, :]\n",
    "    err.append(np.sum((temp - matrix_dist_ranking) ** 2)/2)\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e666f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., -38., -40.,  20., -63., -10.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(err) - err[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a805b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
